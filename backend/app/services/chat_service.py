# backend/app/services/chat_service.py
from app.clients.openai_client import client
from app.schemas.chat import ChatRequest, ChatMessage
from typing import List
import logging

logger = logging.getLogger(__name__)

def build_openai_messages(request: ChatRequest) -> List[dict]:
    """Convert ChatRequest to OpenAI message format"""
    logger.info("ğŸ”§ Building OpenAI messages from conversation history...")
    logger.info(f"ğŸ“ Conversation history length: {len(request.conversation_history)} messages")
    
    # Start with a concise system message to set behavior
    messages = [
        {
            "role": "system",
            "content": (
                "You are Visual4Math, an assistant that can generate both text explanations and images. "
                "Never claim you cannot create images. If the user request is vague or lacks a specific math problem, "
                "ask 2-4 concise clarifying questions instead of inventing details. Keep responses short and focused."
            ),
        }
    ]
    
    # Add conversation history
    for i, msg in enumerate(request.conversation_history):
        logger.info(f"ğŸ“œ Processing history message {i+1}: {msg.role} - {msg.content[:100]}..." + ("" if len(msg.content) <= 100 else "..."))
        if msg.image_url:
            logger.info(f"ğŸ–¼ï¸ Message {i+1} includes image: {msg.image_url[:50]}...")
            
        if msg.role == "user":
            if msg.image_url:
                # User message with image
                messages.append({
                    "role": "user",
                    "content": [
                        {"type": "text", "text": msg.content},
                        {"type": "image_url", "image_url": {"url": msg.image_url}}
                    ]
                })
            else:
                # User message text only
                messages.append({"role": "user", "content": msg.content})
        else:  # assistant
            # Assistant messages are always text (OpenAI limitation)
            # But if the assistant generated an image, we add it as a "user" message
            # so GPT can see the previously generated image in future conversations
            if msg.image_url:
                # Add the assistant's text response first
                messages.append({"role": "assistant", "content": msg.content})
                # Then add the generated image as a "user" message so GPT can see it
                messages.append({
                    "role": "user",
                    "content": [
                        {"type": "text", "text": "[Previous image generated by assistant - now visible for analysis]"},
                        {"type": "image_url", "image_url": {"url": msg.image_url}}
                    ]
                })
                logger.info(f"ğŸ”„ Added assistant text + image as user context for future conversation")
            else:
                # Text-only assistant message
                messages.append({"role": "assistant", "content": msg.content})
    
    # Add current user input
    logger.info(f"â• Adding current user input: {request.user_input[:100]}..." + ("" if len(request.user_input) <= 100 else "..."))
    if request.user_image:
        logger.info(f"ğŸ“¸ Current message includes image: {request.user_image[:50]}...")
        messages.append({
            "role": "user",
            "content": [
                {"type": "text", "text": request.user_input},
                {"type": "image_url", "image_url": {"url": request.user_image}}
            ]
        })
    else:
        messages.append({"role": "user", "content": request.user_input})
    
    logger.info(f"âœ… Built {len(messages)} messages for OpenAI API")
    return messages

def get_text_response(request: ChatRequest) -> str:
    """Get text response from GPT"""
    logger.info("ğŸ“ Generating text response...")
    messages = build_openai_messages(request)
    
    try:
        logger.info(f"ğŸ”— DEBUG: Connecting to OpenAI for text generation...")
        logger.info(f"ğŸ¤– DEBUG: Using model 'gpt-4o' for text generation")
        logger.info(f"ğŸ“Š DEBUG: Sending {len(messages)} messages to OpenAI")
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=messages,
            stream=False
        )
        text_result = response.choices[0].message.content
        logger.info(f"âœ… Text response generated successfully: {len(text_result)} characters")
        logger.info(f"ğŸ“„ Response preview: {text_result[:200]}..." + ("" if len(text_result) <= 200 else "..."))
        return text_result
    except Exception as e:
        logger.error(f"âŒ Text generation failed: {type(e).__name__}: {e}")
        raise e

def get_text_response_stream(request: ChatRequest):
    """Get streaming text response from GPT"""
    logger.info("ğŸŒŠ Generating streaming text response...")
    messages = build_openai_messages(request)
    
    try:
        logger.info("ğŸ”— DEBUG: Connecting to OpenAI for streaming text generation...")
        logger.info("ğŸ¤– DEBUG: Using model 'gpt-4o' for streaming text generation")
        logger.info(f"ğŸ“Š DEBUG: Sending {len(messages)} messages to OpenAI")
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=messages,
            stream=True
        )
        
        logger.info("âœ… Streaming response started")
        chunk_count = 0
        for chunk in response:
            if chunk.choices[0].delta.content is not None:
                chunk_count += 1
                yield chunk.choices[0].delta.content
        logger.info(f"âœ… Streaming complete: {chunk_count} chunks sent")
    except Exception as e:
        logger.error(f"âŒ Streaming text generation failed: {type(e).__name__}: {e}")
        raise e

