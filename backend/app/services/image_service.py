# backend/app/services/image_service.py
from app.clients.openai_client import client
from app.schemas.chat import ChatRequest
from app.services.image_storage_service import store_image
import logging
import base64

logger = logging.getLogger(__name__)

def get_image_response(request: ChatRequest) -> str:
    """Generate image using GPT-4o-image"""
    logger.info("ğŸ¨ Starting image generation...")
    logger.info(f"ğŸ” DEBUG: Full user input for image generation: '{request.user_input}'")
    logger.info(f"ğŸ“ DEBUG: User input length: {len(request.user_input)} characters")
    
    try:
        # Build complete context from conversation history
        # Extract the actual math problem from conversation history
        math_problem = None
        context_parts = []
        
        for msg in request.conversation_history:
            content = getattr(msg, 'content', '') or ''
            role = getattr(msg, 'role', 'unknown')
            
            # Look for word problems (questions with numbers)
            if '?' in content and any(ch.isdigit() for ch in content):
                # This looks like a math problem
                if not math_problem or len(content) > len(math_problem):
                    math_problem = content
            
            context_parts.append(f"{role}: {content}")
        
        context = "\n".join(context_parts)
        
        # Use the math problem if found, otherwise use current request
        target_problem = math_problem if math_problem else request.user_input
        
        # The prompt already contains detailed layout specification from frontend
        # Just use it directly - it includes explicit count requirements and spatial relationships
        prompt = request.user_input
        
        logger.info(f"ğŸ–¼ï¸ DEBUG: Image prompt prepared: {len(prompt)} characters")
        logger.info(f"ğŸ¨ DEBUG: Generating mathematical visualization...")        
        logger.info(f"ğŸ¤– DEBUG: Using model 'gpt-image-1' for image generation...")
        logger.info("=" * 80)
        logger.info("ğŸš€ CALLING OPENAI IMAGES.GENERATE API NOW (with streaming)")
        logger.info(f"ğŸ“ Prompt preview: {prompt[:300]}...")
        logger.info("=" * 80)
        
        # Use images.generate API with text-based layout prompt
        response = client.images.generate(
            model="gpt-image-1",
            prompt=prompt,
            n=1,
            size="1024x1024",
            stream=True,
            partial_images=2
        )

        # Process streaming response - collect final image
        final_image_base64 = None
        
        logger.info("ğŸŒŠ Processing streaming image generation...")
        partial_count = 0
        for event in response:
            event_type = getattr(event, 'type', None)
            logger.info(f"ğŸ“¦ Event type: {event_type}")
            
            if event_type == "image_generation.partial_image":
                partial_idx = getattr(event, 'partial_image_index', None)
                partial_b64 = getattr(event, 'b64_json', None)
                if partial_b64:
                    partial_count += 1
                    logger.info(f"ğŸ“¸ Received partial image {partial_idx} ({len(partial_b64)} chars)")
            elif event_type == "image_generation.completed":
                final_b64 = getattr(event, 'b64_json', None)
                if final_b64:
                    final_image_base64 = final_b64
                    logger.info(f"âœ… Received final image (base64 length: {len(final_b64)} chars) after {partial_count} partial images")
                    break
        
        if final_image_base64:
            data_url = f"data:image/png;base64,{final_image_base64}"
            logger.info(f"âœ… Image generated successfully (base64 format): {len(final_image_base64)} chars")
            # Store the base64 image locally and return our backend URL
            backend_url = store_image(data_url)
            logger.info(f"ğŸ”— Stored base64 image, returning backend URL: {backend_url}")
            return backend_url
        else:
            logger.error("âŒ No final image received from streaming response")
            return ""
    except Exception as e:
        logger.error(f"âŒ Image generation failed: {type(e).__name__}: {e}")
        return ""

def get_image_response_stream(request: ChatRequest):
    """
    Stream image generation with partial images for better UX.
    Yields partial images and final image as they arrive.
    """
    logger.info("ğŸŒŠ Starting streaming image generation...")
    
    # Build prompt (same as non-streaming version)
    math_problem = None
    context_parts = []
    
    for msg in request.conversation_history:
        content = getattr(msg, 'content', '') or ''
        role = getattr(msg, 'role', 'unknown')
        
        if '?' in content and any(ch.isdigit() for ch in content):
            if not math_problem or len(content) > len(math_problem):
                math_problem = content
        
        context_parts.append(f"{role}: {content}")
    
    context = "\n".join(context_parts)
    target_problem = math_problem if math_problem else request.user_input
    
    # The prompt already contains detailed layout specification from frontend
    prompt = request.user_input
    
    logger.info(f"ğŸŒŠ Streaming image generation with prompt ({len(prompt)} chars)...")
    
    try:
        # Use images.generate API with text-based layout prompt
        response = client.images.generate(
            model="gpt-image-1",
            prompt=prompt,
            n=1,
            size="1024x1024",
            stream=True,
            partial_images=2
        )
        
        partial_count = 0
        for event in response:
            event_type = getattr(event, 'type', None)
            
            if event_type == "image_generation.partial_image":
                partial_idx = getattr(event, 'partial_image_index', None)
                partial_b64 = getattr(event, 'b64_json', None)
                if partial_b64:
                    partial_count += 1
                    logger.info(f"ğŸ“¸ Yielding partial image {partial_idx}")
                    yield {
                        'type': 'partial_image',
                        'index': partial_idx,
                        'image_b64': partial_b64
                    }
            elif event_type == "image_generation.completed":
                final_b64 = getattr(event, 'b64_json', None)
                if final_b64:
                    logger.info(f"âœ… Yielding final image after {partial_count} partial images")
                    # Store final image
                    data_url = f"data:image/png;base64,{final_b64}"
                    backend_url = store_image(data_url)
                    yield {
                        'type': 'completed',
                        'image_url': backend_url
                    }
                    break
    except Exception as e:
        logger.error(f"âŒ Streaming image generation failed: {type(e).__name__}: {e}")
        yield {
            'type': 'error',
            'message': str(e)
        }

