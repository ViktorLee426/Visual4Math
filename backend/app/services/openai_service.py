# backend/app/services/openai_service.py
from openai import OpenAI
import os
from dotenv import load_dotenv
from typing import List, Optional
from app.schemas.chat import ChatMessage, ChatRequest, ChatResponse

load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")
client = OpenAI(api_key=api_key)

# Helper Functions
def build_openai_messages(request: ChatRequest) -> List[dict]:
    """Convert ChatRequest to OpenAI message format"""
    messages = [{
        "role": "system", 
        "content": "You are Visual4Math, an expert mathematical assistant. You goal is to help teachers to genereate mathmetical visuals that illustrate math word problems."
    }]
    
    # Add conversation history
    for msg in request.conversation_history:
        if msg.role == "user":
            if msg.image_url:
                # User message with image
                messages.append({
                    "role": "user",
                    "content": [
                        {"type": "text", "text": msg.content},
                        {"type": "image_url", "image_url": {"url": msg.image_url}}
                    ]
                })
            else:
                # User message text only
                messages.append({"role": "user", "content": msg.content})
        else:  # assistant
            # Assistant messages are always text (OpenAI limitation)
            # But if the assistant generated an image, we add it as a "user" message
            # so GPT can see the previously generated image in future conversations
            if msg.image_url:
                # Add the assistant's text response first
                messages.append({"role": "assistant", "content": msg.content})
                # Then add the generated image as a "user" message so GPT can see it
                messages.append({
                    "role": "user",
                    "content": [
                        {"type": "text", "text": "[Previous image generated by assistant - now visible for analysis]"},
                        {"type": "image_url", "image_url": {"url": msg.image_url}}
                    ]
                })
            else:
                # Text-only assistant message
                messages.append({"role": "assistant", "content": msg.content})
    
    # Add current user input
    if request.user_image:
        messages.append({
            "role": "user",
            "content": [
                {"type": "text", "text": request.user_input},
                {"type": "image_url", "image_url": {"url": request.user_image}}
            ]
        })
    else:
        messages.append({"role": "user", "content": request.user_input})
    
    return messages

def analyze_intent(request: ChatRequest) -> str:
    """Use GPT-4 to determine if user wants text, image, or both"""
    analysis_prompt = f"""Analyze this user request and determine the output modality needed.

User input: "{request.user_input}"

Respond with exactly one word:
- "text" - if user wants explanation/answer in text only
- "image" - if user wants visual/diagram as output only  
- "both" - if user wants explanation AND visual in the output at the same time

Output modality:"""

    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": analysis_prompt}],
        max_tokens=10,
        temperature=0
    )
    
    result = response.choices[0].message.content.strip().lower()
    return result if result in ["text", "image", "both"] else "text"

def get_text_response(request: ChatRequest) -> str:
    """Get text response from GPT"""
    messages = build_openai_messages(request)
    
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=messages,
        stream=False  # Keep non-streaming for now, will add streaming endpoint separately
    )
    return response.choices[0].message.content

def get_text_response_stream(request: ChatRequest):
    """Get streaming text response from GPT"""
    messages = build_openai_messages(request)
    
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=messages,
        stream=True
    )
    
    for chunk in response:
        if chunk.choices[0].delta.content is not None:
            yield chunk.choices[0].delta.content

def get_image_response(request: ChatRequest) -> str:
    """Generate image using GPT-Image-1"""
    try:
        # Build complete context from conversation history
        context = ""
        for msg in request.conversation_history:
            context += f"{msg.role}: {msg.content}\n"
        
        prompt = f"""Create a clear, educational mathematical visualization.

Conversation context:
{context}

Current request: {request.user_input}

Create an mathematical visual to illustrate the user's request of the math word problem."""
        
        print(f"ğŸ¨ Generating mathematical visualization...")
        
        # Make the API call
        response = client.images.generate(
            model="gpt-image-1",
            prompt=prompt,
            n=1,
            size="1024x1024"
        )
        
        if response.data and len(response.data) > 0:
            image_data = response.data[0]
            
            # Handle base64 response (expected format)
            if hasattr(image_data, 'b64_json') and image_data.b64_json:
                base64_data = image_data.b64_json
                data_url = f"data:image/png;base64,{base64_data}"
                print(f"âœ… Image generated successfully")
                return data_url
            # Fallback for URL response
            elif hasattr(image_data, 'url') and image_data.url:
                print(f"âœ… Image generated successfully")
                return image_data.url
            else:
                print("âŒ No image data found in response")
                return ""
        else:
            print("âŒ No image data in response")
            return ""
            
    except Exception as e:
        print(f"âŒ Image generation failed: {str(e)}")
        raise e

def process_conversation(request: ChatRequest) -> ChatResponse:
    """Main function: Process user input and return appropriate response"""
    if not request.user_input.strip():
        return ChatResponse(
            type="text",
            content="Please provide a message or question.",
            image_url=None
        )
    
    # Analyze what the user wants
    intent = analyze_intent(request)
    print(f"ğŸ§  Detected intent: {intent} for input: '{request.user_input}'")
    
    try:
        if intent == "text":
            # Just text response
            print("ğŸ“ Processing text-only response...")
            text_content = get_text_response(request)
            return ChatResponse(
                type="text",
                content=text_content,
                image_url=None
            )
        
        elif intent == "image":
            print("ğŸ¨ Processing image-only response...")
            image_url = get_image_response(request)
            return ChatResponse(
                type="image",
                content="Here's the mathematical visual that you requested:",
                image_url=image_url
            )
        
        elif intent == "both":
            # Get text response
            print("ğŸ¯ Processing both text and image response...")
            enhanced_request = ChatRequest(
                user_input=f"{request.user_input}\n[Note: A visual diagram will accompany this response.]",
                user_image=request.user_image,
                conversation_history=request.conversation_history
            )
            text_content = get_text_response(enhanced_request)
            image_url = get_image_response(request)
            
            return ChatResponse(
                type="both",
                content=text_content + "\n\nğŸ“Š See the diagram above for a visual representation.",
                image_url=image_url
            )
    
    except Exception as e:
        print(f"âŒ Error in process_conversation: {type(e).__name__}: {e}")
        return ChatResponse(
            type="text",
            content="I encountered an error processing your request. Please try again.",
            image_url=None
        )
