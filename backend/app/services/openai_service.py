"""
OpenAI service for chat and image generation.

Handles communication with OpenAI API including GPT-4 Vision for text/image understanding
and DALL-E for image generation.
"""
from openai import OpenAI
import os
from dotenv import load_dotenv
from typing import List, Optional
from app.schemas.chat import ChatMessage, ChatRequest, ChatResponse
import logging

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Load .env file efficiently (don't scan parent directories)
backend_dir = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
env_path = os.path.join(backend_dir, '.env')
if os.path.exists(env_path):
    load_dotenv(dotenv_path=env_path, override=False)
else:
    load_dotenv(override=False)

# Lazy initialization to prevent hanging during import
_client_instance = None
def get_client():
    global _client_instance
    if _client_instance is None:
        api_key = os.getenv("OPENAI_API_KEY")
        _client_instance = OpenAI(api_key=api_key)
    return _client_instance

# For backward compatibility
class ClientProxy:
    def __getattr__(self, name):
        return getattr(get_client(), name)
client = ClientProxy()

# Helper Functions
def build_openai_messages(request: ChatRequest) -> List[dict]:
    """Convert ChatRequest to OpenAI message format"""
    logger.info("ğŸ”§ Building OpenAI messages from conversation history...")
    logger.info(f"ğŸ“ Conversation history length: {len(request.conversation_history)} messages")
    
    # Start with empty messages - no system prompt for clean ChatGPT-like experience
    messages = []
    
    # Add conversation history
    for i, msg in enumerate(request.conversation_history):
        logger.info(f"ğŸ“œ Processing history message {i+1}: {msg.role} - {msg.content[:100]}..." + ("" if len(msg.content) <= 100 else "..."))
        if msg.image_url:
            logger.info(f"ğŸ–¼ï¸ Message {i+1} includes image: {msg.image_url[:50]}...")
            
        if msg.role == "user":
            if msg.image_url:
                # User message with image
                messages.append({
                    "role": "user",
                    "content": [
                        {"type": "text", "text": msg.content},
                        {"type": "image_url", "image_url": {"url": msg.image_url}}
                    ]
                })
            else:
                # User message text only
                messages.append({"role": "user", "content": msg.content})
        else:  # assistant
            # Assistant messages are always text (OpenAI limitation)
            # But if the assistant generated an image, we add it as a "user" message
            # so GPT can see the previously generated image in future conversations
            if msg.image_url:
                # Add the assistant's text response first
                messages.append({"role": "assistant", "content": msg.content})
                # Then add the generated image as a "user" message so GPT can see it
                messages.append({
                    "role": "user",
                    "content": [
                        {"type": "text", "text": "[Previous image generated by assistant - now visible for analysis]"},
                        {"type": "image_url", "image_url": {"url": msg.image_url}}
                    ]
                })
                logger.info(f"ğŸ”„ Added assistant text + image as user context for future conversation")
            else:
                # Text-only assistant message
                messages.append({"role": "assistant", "content": msg.content})
    
    # Add current user input
    logger.info(f"â• Adding current user input: {request.user_input[:100]}..." + ("" if len(request.user_input) <= 100 else "..."))
    if request.user_image:
        logger.info(f"ğŸ“¸ Current message includes image: {request.user_image[:50]}...")
        messages.append({
            "role": "user",
            "content": [
                {"type": "text", "text": request.user_input},
                {"type": "image_url", "image_url": {"url": request.user_image}}
            ]
        })
    else:
        messages.append({"role": "user", "content": request.user_input})
    
    logger.info(f"âœ… Built {len(messages)} messages for OpenAI API (including system message)")
    return messages

def analyze_intent(request: ChatRequest) -> str:
    """Use GPT-4o to determine if user wants text or image"""
    logger.info("ğŸ§  Analyzing user intent with GPT-4o...")

    analysis_prompt = f"""Analyze this user request and determine the output modality needed.

User input: "{request.user_input}"

Analyze user's input and decide the modality of the output. You will respond with exactly one word:

- "text" - if user wants explanation/answer in text (DEFAULT - use this unless explicitly asking for visuals)
- "image" - if user explicitly wants visual/diagram as output

Output modality:"""

    try:
        logger.info("ğŸ”— DEBUG: Connecting to OpenAI for intent analysis...")
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": analysis_prompt}],
            max_tokens=10,
            temperature=0
        )
        
        raw_result = response.choices[0].message.content
        result = raw_result.strip().lower() if raw_result else ""
        # Only accept text or image as valid intents
        final_intent = "text" if result != "image" else "image"
        logger.info(f"ï¿½ DEBUG: GPT-4o intent analysis result: '{result}', final intent: '{final_intent}'")
        
        return final_intent
    except Exception as e:
        logger.error(f"âŒ Intent analysis failed: {type(e).__name__}: {e}")
        logger.info("ğŸ”„ Falling back to 'text' intent")
        return "text"


def get_text_response(request: ChatRequest) -> str:
    """Get text response from GPT"""
    logger.info("ğŸ“ Generating text response..., function call from openai_service.py, with get_text_response()")
    messages = build_openai_messages(request)
    
    try:
        logger.info(f"ğŸ”— DEBUG: Connecting to OpenAI for text generation...")
        logger.info(f"ğŸ¤– DEBUG: Using model 'gpt-4o' for text generation")
        logger.info(f"ğŸ“Š DEBUG: Sending {len(messages)} messages to OpenAI")
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=messages,
            stream=False  # Keep non-streaming for now, will add streaming endpoint separately
        )
        text_result = response.choices[0].message.content
        logger.info(f"âœ… Text response generated successfully: {len(text_result)} characters")
        logger.info(f"ğŸ“„ Response preview: {text_result[:200]}..." + ("" if len(text_result) <= 200 else "..."))
        return text_result
    except Exception as e:
        logger.error(f"âŒ Text generation failed: {type(e).__name__}: {e}")
        raise e

def get_text_response_stream(request: ChatRequest):
    """Get streaming text response from GPT"""
    logger.info("ğŸŒŠ Generating streaming text response..., function call from openai_service.py, with get_text_response_stream()")
    messages = build_openai_messages(request)
    
    try:
        logger.info("ğŸ”— DEBUG: Connecting to OpenAI for streaming text generation...")
        logger.info("ğŸ¤– DEBUG: Using model 'gpt-4o' for streaming text generation")
        logger.info(f"ğŸ“Š DEBUG: Sending {len(messages)} messages to OpenAI")
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=messages,
            stream=True
        )
        
        logger.info("âœ… Streaming response started")
        chunk_count = 0
        for chunk in response:
            if chunk.choices[0].delta.content is not None:
                chunk_count += 1
                yield chunk.choices[0].delta.content
        logger.info(f"âœ… Streaming complete: {chunk_count} chunks sent")
    except Exception as e:
        logger.error(f"âŒ Streaming text generation failed: {type(e).__name__}: {e}")
        raise e

def get_image_response(request: ChatRequest) -> str:
    """Generate image using GPT-4o-image"""
    logger.info("ğŸ¨ Starting image generation..., function call from openai_service.py, with get_image_response()")
    logger.info(f"ğŸ” DEBUG: Full user input for image generation: '{request.user_input}'")
    logger.info(f"ğŸ“ DEBUG: User input length: {len(request.user_input)} characters")
    
    try:
        # Build complete context from conversation history
        context = ""
        for msg in request.conversation_history:
            context += f"{msg.role}: {msg.content}\n"
        
        prompt = f"""Create a clear, educational mathematical visualization 

Conversation context:
{context}

Current request: {request.user_input}

Create a detailed, mathematically precise visual illustration for this educational scenario. """
        
        logger.info(f"ğŸ–¼ï¸ DEBUG: Image prompt prepared: {len(prompt)} characters")
        logger.info(f"ğŸ¨ DEBUG: Generating mathematical visualization...")        
        # Make the API call with GPT-4o's image generation capability
        logger.info(f"ğŸ¤– DEBUG: Using model 'gpt-4o-image' for image generation...")
        
        response = client.images.generate(
            model="gpt-image-1",
            prompt=prompt,
            n=1,
            size="1024x1024"
        )

        logger.info(f"ğŸ“¦ DEBUG: Response type: {type(response)}")
        logger.info(f"ğŸ“¦ DEBUG: Response data length: {len(response.data) if response.data else 0}")
        
        if response.data and len(response.data) > 0:
            image_data = response.data[0]
            logger.info(f"ğŸ“¦ DEBUG: Received image data: {type(image_data)}")
            
            # GPT-4o-image with URL format - prioritize URL for efficiency
            if hasattr(image_data, 'url') and image_data.url:
                logger.info(f"âœ… Image generated successfully (URL format): {image_data.url}")
                return image_data.url
            # Fallback for base64 response (if available)
            elif hasattr(image_data, 'b64_json') and image_data.b64_json:
                base64_data = image_data.b64_json
                data_url = f"data:image/png;base64,{base64_data}"
                logger.info(f"âœ… Image generated successfully (base64 format): {len(base64_data)} chars")
                logger.info(f"ğŸ”— DEBUG: Base64 data URL created: data:image/png;base64,{base64_data[:50]}...")
                return data_url
            else:
                logger.error("âŒ No image data found in response - missing both url and b64_json")
                logger.info(f"ğŸ” Available attributes: {dir(image_data)}")
                if hasattr(image_data, '__dict__'):
                    logger.info(f"ğŸ” Image data dict: {image_data.__dict__}")
                return ""
        else:
            logger.error("âŒ No image data in response - empty response.data")
            return ""
            
    except Exception as e:
        logger.error(f"âŒ Image generation failed: {type(e).__name__}: {e}")
        logger.error(f"ğŸ” Full error details: {str(e)}")
        raise e

def process_conversation(request: ChatRequest, intent: str = None) -> ChatResponse:
    """Main function: Process user input and return appropriate response"""
    logger.info("ğŸš€ Starting conversation processing... function call from openai_service.py, with process_conversation()")
    
    if not request.user_input.strip():
        logger.warning("âš ï¸ Empty user input received")
        return ChatResponse(
            type="text",
            content="Please provide a message or question.",
            image_url=None
        )
    
    # Only analyze intent if not provided
    if intent is None:
        logger.info("ğŸ§  No intent provided, analyzing user intent...")
        intent = analyze_intent(request)
    else:
        logger.info(f"ğŸ§  Using provided intent: {intent}")

    try:
        if intent == "text":
            # Just text response
            logger.info("ğŸ“ DEBUG: Processing text-only response...")
            text_content = get_text_response(request)
            result = ChatResponse(
                type="text",
                content=text_content,
                image_url=None
            )
            logger.info(f"âœ… DEBUG: Text-only response complete: {len(text_content)} characters")
            return result
        
        elif intent == "image":
            logger.info("ğŸ¨ DEBUG: Processing image-only response...")
            image_url = get_image_response(request)
            result = ChatResponse(
                type="image",
                content="Here's the mathematical visual that you requested:",
                image_url=image_url
            )
            logger.info(f"âœ… DEBUG: Image-only response complete: {len(image_url)} chars image URL")
            return result
        
        # We no longer support the "both" modality - removed for simplicity
    
    except Exception as e:
        logger.error(f"âŒ Error in process_conversation: {type(e).__name__}: {e}")
        logger.error(f"ğŸ” Full error details: {str(e)}")
        return ChatResponse(
            type="text",
            content="I encountered an error processing your request. Please try again.",
            image_url=None
        )
