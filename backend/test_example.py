# Example test script demonstrating the Visual4Math backend usage
# This shows how the conversation flow would work

from app.schemas.chat import ChatMessage, ChatRequest, ChatResponse
from app.services.conversation_service import process_conversation
from app.services.intent_service import analyze_intent

# Example 1: Text-only question
def test_text_question():
    print("=== Test 1: Text-only question ===")
    request = ChatRequest(
        user_input="What is the derivative of x^2?",
        user_image=None,
        conversation_history=[]
    )
    
    intent = analyze_intent(request)
    print(f"Detected intent: {intent}")
    print(f"User input: {request.user_input}")
    print()

# Example 2: Request for visualization
def test_image_request():
    print("=== Test 2: Request for visualization ===")
    request = ChatRequest(
        user_input="Please draw a graph of the function y = x^2",
        user_image=None,
        conversation_history=[]
    )
    
    intent = analyze_intent(request)
    print(f"Detected intent: {intent}")
    print(f"User input: {request.user_input}")
    print()

# Example 3: Request for both explanation and visual
def test_both_request():
    print("=== Test 3: Request for both explanation and visual ===")
    request = ChatRequest(
        user_input="Explain the concept of derivatives and show me a visual example",
        user_image=None,
        conversation_history=[]
    )
    
    intent = analyze_intent(request)
    print(f"Detected intent: {intent}")
    print(f"User input: {request.user_input}")
    print()

# Example 4: Follow-up conversation with generated image history
def test_conversation_with_generated_image():
    print("=== Test 4: Conversation with generated image history ===")
    
    # Simulate previous conversation where assistant generated an image
    history = [
        ChatMessage(
            role="user",
            content="Can you show me a graph of y = x^2?",
            image_url=None
        ),
        ChatMessage(
            role="assistant",
            content="Here's a graph of the parabola y = x^2. As you can see, it's a U-shaped curve that opens upward...",
            image_url="https://example.com/generated_parabola.jpg"  # Generated by DALL-E
        )
    ]
    
    # Now user asks a follow-up that references the previous image
    request = ChatRequest(
        user_input="Can you add the tangent line at x=2 to that same graph?",
        user_image=None,
        conversation_history=history
    )
    
    intent = analyze_intent(request)
    print(f"Detected intent: {intent}")
    print(f"User input: {request.user_input}")
    print(f"Previous assistant generated image: {history[1].image_url}")
    print("✓ GPT will be able to see the previously generated image!")
    print()

# Example 5: Chain of visual improvements
def test_visual_iteration():
    print("=== Test 5: Chain of visual improvements ===")
    
    # Multiple rounds of image generation and improvement
    history = [
        ChatMessage(
            role="user",
            content="Draw a simple coordinate system",
            image_url=None
        ),
        ChatMessage(
            role="assistant",
            content="I've created a basic coordinate system with x and y axes.",
            image_url="https://example.com/coordinate_system.jpg"
        ),
        ChatMessage(
            role="user",
            content="Now add grid lines to make it easier to read",
            image_url=None
        ),
        ChatMessage(
            role="assistant",
            content="I've added grid lines to the coordinate system to make it more readable.",
            image_url="https://example.com/coordinate_system_with_grid.jpg"
        )
    ]
    
    request = ChatRequest(
        user_input="Perfect! Now can you plot the function y = sin(x) on this grid?",
        user_image=None,
        conversation_history=history
    )
    
    intent = analyze_intent(request)
    print(f"Detected intent: {intent}")
    print(f"User input: {request.user_input}")
    print(f"Conversation history length: {len(request.conversation_history)}")
    print("✓ GPT can see both previous coordinate systems and build upon them!")
    print()

# Example 5: User uploads an image
def test_user_image():
    print("=== Test 5: User uploads an image ===")
    request = ChatRequest(
        user_input="Can you help me solve this math problem?",
        user_image="https://example.com/math_problem.jpg",
        conversation_history=[]
    )
    
    intent = analyze_intent(request)
    print(f"Detected intent: {intent}")
    print(f"User input: {request.user_input}")
    print(f"User image: {request.user_image}")
    print()

if __name__ == "__main__":
    print("Visual4Math Backend Test Examples")
    print("=" * 40)
    print()
    
    test_text_question()
    test_image_request()
    test_both_request()
    test_conversation_with_generated_image()
    test_visual_iteration()
    test_user_image()
    
    print("Note: These are intent analysis tests.")
    print("To test actual OpenAI API calls, you need:")
    print("1. Set OPENAI_API_KEY environment variable")
    print("2. Install required packages: pip install openai python-dotenv")
    print("3. Use: response = process_conversation(request)")
